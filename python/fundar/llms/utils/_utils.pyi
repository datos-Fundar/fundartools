import uuid
from _typeshed import Incomplete
from collections.abc import Iterable
from copy import copy as copy
from langchain.document_loaders import PyPDFLoader
from langchain_core.documents import Document
from pydantic import Field as Field
from tqdm.contrib.concurrent import process_map as process_map
from typing import Sequence, TypeVar

T = TypeVar('T')

def flatten(nested_list: Sequence[Sequence[T]], max_level: int = 5) -> Sequence[T]: ...
def split_list_into_chunks(lst: list[T], chunk_size: int): ...
def pass_generator_as_copy(*xs): ...
def allow_opaque_constructor(**objects): ...
def consume(iterator, n: Incomplete | None = None) -> None: ...
def is_cuda_available() -> bool: ...

class UuidGenerator:
    seed: Incomplete
    def __init__(self, seed: int | None = None) -> None: ...
    def reset(self): ...
    def next(self, n: int | None = None): ...
    def __iter__(self): ...
    def map(self, xs: Iterable[T], offset: int | None = None) -> Iterable[uuid.UUID]: ...
    def zipWith(self, xs: Iterable[T], offset: int | None = None) -> Iterable[tuple[uuid.UUID, T]]: ...
DEFAULT_PDF_LOADER = PyPDFLoader

def load_document(filepath: str, loader: Incomplete | None = None, seed_id: int | None = -1) -> list[Document]: ...

DEFAULT_RCT_SPLITTER: Incomplete

def split_document(xs, splitter: Incomplete | None = None, seed_id: int | None = -1) -> list[Document]: ...
def load_and_split(filepath: str, loader: Incomplete | None = None, splitter: Incomplete | None = None, seed_id: int | None = -1, flatten: bool = True): ...
def SentenceTransformer(*args, **kwargs): ...
def encode_with_multiprocessing(transformer, pool): ...
def vectorize_document(x: str | Document | Iterable[Document | str], sentence_transformer: Incomplete | None = None, uid: Incomplete | None = None, additional_metadata=..., devices: Incomplete | None = None): ...
def available_vram_nvidia_smi(): ...
def available_vram_torch(): ...
def get_available_vram(): ...
def splitmodel(x) -> tuple[str, str]: ...
def modelname(x): ...
def modelspecs(x): ...
